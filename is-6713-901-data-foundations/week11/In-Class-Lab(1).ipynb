{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf686b-2b77-479b-b380-85b8be06c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES\n",
    "\n",
    "# Questions?\n",
    "\n",
    "# Feature Generation, i.e., converting data into a matrix of numbers\n",
    "\n",
    "## DictVectorizer\n",
    "\n",
    "## CountVectorizer\n",
    "\n",
    "## Custom (using numpy)\n",
    "\n",
    "# General Machine Learning Pipeline\n",
    "\n",
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53382ea-8ef5-4dc4-8c97-4ee0a87a777e",
   "metadata": {},
   "source": [
    "# Exercise 1: Understand your data\n",
    "\n",
    "Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. This is important as a health and development issue at a national, regional and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions. Yet, water drinkability is measured by multiple factors, many of which can not be used alone. Hence, this exercise we will develop methods of predicting whether water is drinkable based on variuos measured characteristics.\n",
    "\n",
    "**YOUR TASK:** The first step is to **understand your data**. For each column in the dataset, label whether it is a categorical, ordinal, binary, or numeric value.\n",
    "\n",
    "1. ph: pH of 1. water (0 to 14).\n",
    "    1. Data Type: \n",
    "2. Hardness: Capacity of water to precipitate soap in mg/L.\n",
    "    1. Data Type: \n",
    "3. Solids: Total dissolved solids in ppm.\n",
    "    1. Data Type: \n",
    "4. Chloramines: Amount of Chloramines in ppm.\n",
    "    1. Data Type: \n",
    "5. Sulfate: Amount of Sulfates dissolved in mg/L.\n",
    "    1. Data Type: \n",
    "6. Conductivity: Electrical conductivity of water in μS/cm.\n",
    "    1. Data Type: \n",
    "7. Organic_carbon: Amount of organic carbon in ppm.\n",
    "    1. Data Type: \n",
    "8. Trihalomethanes: Amount of Trihalomethanes in μg/L.\n",
    "    1. Data Type: \n",
    "9. Turbidity: Measure of light emiting property of water in NTU.\n",
    "    1. Data Type: \n",
    "10. Potability: Indicates if water is safe for human consumption. Potable (1) and Not potable (0) (This is what you will predict).\n",
    "    1. Data Type: \n",
    "    \n",
    "**TIME**: 10 Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c9bba-8a41-4843-b873-51586e6fd3d8",
   "metadata": {},
   "source": [
    "# Exercise 2: Create Splits and Explore your data\n",
    "\n",
    "After splitting the dataset and converting the data into a matrix, answer the following questions:\n",
    "1. How many **columns** does the **training data** have?\n",
    "2. How many **rows** does the **training data** have?\n",
    "3. How many **columns** does the **test data** have?\n",
    "4. How many **rows** does the **test data** have?\n",
    "5. What is the max value in each column of the **training data**?\n",
    "6. What is the min value in each column of the **training data**?\n",
    "7. What is the mean value in each column of the **training data**?\n",
    "\n",
    "**TIME**: 10 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d1dea7-cead-41fa-880f-256a207a5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import csv\n",
    "\n",
    "X_dict = []\n",
    "y = []\n",
    "with open('water_potability.csv') as iFile:\n",
    "    iCSV = csv.reader(iFile, delimiter=',')\n",
    "    next(iCSV)\n",
    "    # ph,Hardness,Solids,Chloramines,Sulfate,Conductivity,Organic_carbon,Trihalomethanes,Turbidity,Potability\n",
    "    for row in iCSV:\n",
    "        data = {}\n",
    "        data['ph'] = float(row[0])\n",
    "        data['Hardness'] = float(row[1])\n",
    "        data['Solids'] = float(row[2])\n",
    "        data['Chloramines'] = float(row[3])\n",
    "        data['Sulfate'] = float(row[4])\n",
    "        data['Conductivity'] = float(row[5])\n",
    "        data['Organic_carbon'] = float(row[6])\n",
    "        data['Trihalomethanes'] = float(row[7])\n",
    "        data['Turbidity'] = float(row[8])\n",
    "        X_dict.append(data)\n",
    "        y.append(int(row[-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ce519-afa6-4c6a-b2e8-037e49c433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ab9ba-1a44-4b7d-99ac-6c395fb21d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12ac47-3a3a-467f-983c-5dc36db80db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "######################\n",
    "# Split dataset into a training and testing portion here.\n",
    "\n",
    "X_train_dict, X_test_dict, y_train, y_test = ... # Replace the ... with your code to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b956315-3e6e-4b97-b48d-9d0cf7cd619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates the matrix from each list of dictionaries.  You do NOT need to edit this.\n",
    "vec = DictVectorizer()\n",
    "\n",
    "X_train = vec.fit_transform(X_train_dict)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f89e9-3003-48bf-b5a9-e9795bb841e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CODE TO ANSWER QUESTIONS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e8a4c-529c-4e50-b941-e5184f46bf05",
   "metadata": {},
   "source": [
    "# Exercise 3: Model Selection\n",
    "\n",
    "The data has been split into a training and test dataset. Now, your task is to train a machine learning classifier on the dataset. Specifically, you need to train and evaluate 3 different machine learning models: RandomForestClassifier, SVC, and LogisticRegression. For each classifier, you MUST gridsearch on two of its parameters. You can find the parameters for each model below:\n",
    "\n",
    "1. RandomForestClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    1. I recommend n_estimators and criterion\n",
    "2. SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    1. I recommend C and kernel\n",
    "3. LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    1. I recommend C and fit_intercept\n",
    "    \n",
    "Report the training F1 and cross-validation F1 in the following table:\n",
    "\n",
    "|Model| Training F1 | Validation F1|\n",
    "|----|----|----|\n",
    "|Random Forest | SCORE HERE | SCORE HERE |\n",
    "|SVC | SCORE HERE | SCORE HERE |\n",
    "|LogisticRegression | SCORE HERE | SCORE HERE |\n",
    "\n",
    "Finally, answer the questions: Is the training F1 higher then the validation F1? Why or why not?\n",
    "\n",
    "**TIME**: 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70820720-21cc-4290-9197-2d788fb2efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "params = {}\n",
    "\n",
    "base_clf = ... # The classifier (e.g., LogisticRegression) goes here.\n",
    "\n",
    "clf = GridSearchCV(base_clf, params, cv = 5, scoring='f1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_train)\n",
    "f1 = f1_score(y_train, preds)\n",
    "print(\"Best Parameters:\", clf.best_params_)\n",
    "print(f\"Training F1: {f1:.4f}\") # This is the \"Training F1\"\n",
    "print(f\"Validation F1: {clf.best_score_:.4f}\") # This is the Validation F1 from the cross-validation procedure in GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb41d1-cb78-4580-b146-5f42588ce695",
   "metadata": {},
   "source": [
    "# Exercise 5: Model Assessment\n",
    "\n",
    "Now that you have found the best model, we need to measure how the model will perform on new unseen data. We will use the extrated test data as our \"unseen\" data.\n",
    "\n",
    "**YOUR TASK**: Retrain the best classifier using the best parameters found via GridSearchCV. Note that GridSearchCV is not needed here. Do the final test results match the cross-validation results found via the GridSearchCV method?\n",
    "\n",
    "**TIME**: 10 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc99c3-ad6a-40cf-a66a-f05ac6a3ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "clf = ... # The classififier (e.g., RandomForestClassifier) goes here\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(f\"precision: {precision:.4f}\")\n",
    "print(f\"recall: {recall:.4f}\")\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bd419-79ac-4590-85e9-f435ad2db103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
