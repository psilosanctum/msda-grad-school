{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       parent_id                                               Body  \\\n",
      "515  26179110254  I've been to most of [these](http://maps.googl...   \n",
      "691  26228204990  we have a lot of shows coming up so check out ...   \n",
      "494  26244353104  Cheaper for the tax payer (maybe).  We didn't ...   \n",
      "264  26251770603  I hear ya. I get home from work and get lost i...   \n",
      "409  26302259456  My hard drive is encrypted on my computer. I t...   \n",
      "..           ...                                                ...   \n",
      "343  42172446460  Westside Assistant Principal here. Itâ€™s isnâ...   \n",
      "183  42172924981  Dope manðŸ‘ŒðŸ½ Iâ€™ll have a cooler with som...   \n",
      "475  42172955407  Yeah, where are the 2a nuts now? That kid can ...   \n",
      "359  42174267356                                      I second this   \n",
      "526  42174557317  Haha fair enough. So then itâ€™s either illite...   \n",
      "\n",
      "    Group2_Tech_Annotations Group2_Politics_Annotations  \n",
      "515                       Y                           N  \n",
      "691                       N                           N  \n",
      "494                       N                           N  \n",
      "264                       Y                           N  \n",
      "409                       y                           N  \n",
      "..                      ...                         ...  \n",
      "343                       n                           N  \n",
      "183                       n                           N  \n",
      "475                       N                           Y  \n",
      "359                       N                           N  \n",
      "526                       N                           N  \n",
      "\n",
      "[1003 rows x 4 columns]\n",
      "1003\n",
      "1003\n",
      "1123\n",
      "Group1_Tech_Annotations\n",
      "Y    590\n",
      "N    533\n",
      "Name: count, dtype: int64\n",
      "(561, 8) (562, 8)\n",
      "0.028469750889679714\n",
      "0.06417112299465241\n",
      "Cohen kappa tech score:  0.18599826481135773\n",
      "Cohen kappa politics score:  0.40476298088973073\n"
     ]
    }
   ],
   "source": [
    "from csv import reader, QUOTE_NONE\n",
    "from pandas import set_option, read_excel, read_csv, merge\n",
    "from numpy import array\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "set_option('display.max_columns', None)\n",
    "\n",
    "columns = [\n",
    "    'Group1_Tech_Annotations',\n",
    "    'Group1_Politics_Annotations',\n",
    "    'Group2_Tech_Annotations',\n",
    "    'Group2_Politics_Annotations',\n",
    "    'parent_id',\n",
    "    'Body'\n",
    "]\n",
    "\n",
    "def convert_excel_to_csv():\n",
    "    group1_df = read_excel('group1_annotations.xlsx').rename(\n",
    "        columns = {\n",
    "        'Tech Related': columns[0],\n",
    "        'Politics Related': columns[1],\n",
    "        }\n",
    "    )\n",
    "    group1_df.to_csv('annotations1.csv', index=False)\n",
    "    # print(group1_df)\n",
    "\n",
    "    group2_df = read_excel('group2_annotations.xlsx').rename(\n",
    "        columns = {\n",
    "        'Tech Related': columns[2],\n",
    "        'Politics Related': columns[3],\n",
    "        }\n",
    "    ).sort_values('parent_id')\n",
    "    print(group2_df)\n",
    "    group2_df.to_csv('annotations2.csv', index=False)\n",
    "\n",
    "convert_excel_to_csv()\n",
    "\n",
    "\n",
    "converted_df_to_list = []\n",
    "group1_df = read_csv('annotations1.csv')\n",
    "# for idx, row in group1_df.iterrows():\n",
    "    # print(row[columns[0]].strip)\n",
    "    # row[columns[2]],\n",
    "    # row[columns[1]],\n",
    "    # row[columns[3]],\n",
    "\n",
    "print(group1_df['Body'].count())\n",
    "group2_df = read_csv('annotations2.csv')\n",
    "print(group2_df['Body'].count())\n",
    "merged_df = merge(group1_df, group2_df, on=[columns[4], columns[5]])\n",
    "print(merged_df['Body'].count())\n",
    "merged_df.to_csv('test.csv', index=False)\n",
    "merged_df[columns[0]] = merged_df[columns[0]].str.upper()\n",
    "merged_df[columns[2]] = merged_df[columns[2]].str.upper()\n",
    "merged_df[columns[1]] = merged_df[columns[1]].str.upper()\n",
    "merged_df[columns[3]] = merged_df[columns[3]].str.upper()\n",
    "\n",
    "group1_tech = merged_df[columns[0]].to_numpy(dtype=str)\n",
    "group2_tech = merged_df[columns[2]].to_numpy(dtype=str)\n",
    "group1_politics = merged_df[columns[1]].to_numpy(dtype=str)\n",
    "group2_politics = merged_df[columns[3]].to_numpy(dtype=str)\n",
    "# print(group1_tech)\n",
    "\n",
    "reformat_group1_tech = []\n",
    "for row in group1_tech:\n",
    "    row = row.strip()\n",
    "    if row == 'T':\n",
    "        val = 'Y'\n",
    "        reformat_group1_tech.append(val)\n",
    "    elif row == 'nan':\n",
    "        val = 'Y'\n",
    "        reformat_group1_tech.append(val)\n",
    "    else:\n",
    "        reformat_group1_tech.append(row)\n",
    "group1_tech = reformat_group1_tech\n",
    "\n",
    "reformat_group1_politics = []\n",
    "for row in group1_politics:\n",
    "    row = row.strip()\n",
    "    reformat_group1_politics.append(row)\n",
    "# print(reformat_group1_politics)\n",
    "group1_politics = reformat_group1_politics \n",
    "\n",
    "merged_df[columns[0]] = group1_tech\n",
    "merged_df[columns[1]] = group1_politics\n",
    "print(merged_df['Group1_Tech_Annotations'].value_counts())\n",
    "\n",
    "X_dicts = []\n",
    "y = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    tmp = {\n",
    "        'g1_tech': row[columns[0]],\n",
    "        'g2_tech': row[columns[2]],\n",
    "        'g1_pol': row[columns[1]],\n",
    "        'g2_pol': row[columns[3]],\n",
    "    }\n",
    "    X_dicts.append(tmp)\n",
    "    y.append(row[columns[5]])\n",
    "\n",
    "# print(X_dicts)\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(X_dicts)\n",
    "y = array(y)\n",
    "# print(X)\n",
    "# print(y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape)\n",
    "\n",
    "clf = SVC(C=.1)\n",
    "clf = SVC(C=100.)\n",
    "# clf = SVC(C=10.)\n",
    "# clf = SVC(C=10000.)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_val)\n",
    "print(accuracy_score(y_val, preds))\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, preds))\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "\n",
    "group1_counts = {}\n",
    "for r1, r2 in zip(group1_tech, group2_tech):\n",
    "    group1_counts['r1_'+r1+'_r2_'+r2] = group1_counts.get('r1_'+r1+'_r2_'+r2, 0) + 1\n",
    "# print(group1_counts)\n",
    "\n",
    "group2_counts = {}\n",
    "for r1, r2 in zip(group1_politics, group2_politics):\n",
    "    group2_counts['r1_'+r1+'_r2_'+r2] = group2_counts.get('r1_'+r1+'_r2_'+r2, 0) + 1\n",
    "# print(group2_counts)\n",
    "# print(group1_tech)\n",
    "# print(merged_df)\n",
    "\n",
    "print('Cohen kappa tech score: ', cohen_kappa_score(group1_tech, group2_tech))\n",
    "print('Cohen kappa politics score: ', cohen_kappa_score(group1_politics, group2_politics))\n",
    "\n",
    "\n",
    "# for idx, row in merged_df.iterrows():\n",
    "#     row_list = [row[columns[4]], row[columns[5]], row[columns[0]], row[columns[2]], row[columns[1]], row[columns[3]]]\n",
    "#     converted_df_to_list.append(row_list)\n",
    "# print(converted_df_to_list)\n",
    "\n",
    "# X_txt_train = []\n",
    "# y_train = []\n",
    "# for row in converted_df_to_list:\n",
    "#     print(row)\n",
    "#     X_txt_train.append(row[1])\n",
    "#     y_train.append(row[2:])\n",
    "\n",
    "# print(X_txt_train)\n",
    "# print(y_train)\n",
    "# print(converted_df_to_list)\n",
    "# print(df)\n",
    "# data = open(\"annotations1.csv\")\n",
    "# read_data = reader(data, delimiter='\\t', quoting=QUOTE_NONE)\n",
    "\n",
    "# for row in read_data:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
