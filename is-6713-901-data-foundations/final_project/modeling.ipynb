{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "need to escape, but no escapechar set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(group2_df)\n\u001b[1;32m     39\u001b[0m     group2_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quoting\u001b[38;5;241m=\u001b[39mQUOTE_NONE)\n\u001b[0;32m---> 41\u001b[0m convert_excel_to_csv()\n\u001b[1;32m     44\u001b[0m converted_df_to_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m group1_df \u001b[38;5;241m=\u001b[39m read_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[70], line 29\u001b[0m, in \u001b[0;36mconvert_excel_to_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_excel_to_csv\u001b[39m():\n\u001b[1;32m     23\u001b[0m     group1_df \u001b[38;5;241m=\u001b[39m read_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup1_annotations.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     24\u001b[0m         columns \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTech Related\u001b[39m\u001b[38;5;124m'\u001b[39m: columns[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolitics Related\u001b[39m\u001b[38;5;124m'\u001b[39m: columns[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     27\u001b[0m         }\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m     group1_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quoting\u001b[38;5;241m=\u001b[39mQUOTE_NONE)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# print(group1_df)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     group2_df \u001b[38;5;241m=\u001b[39m read_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup2_annotations.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     33\u001b[0m         columns \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTech Related\u001b[39m\u001b[38;5;124m'\u001b[39m: columns[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolitics Related\u001b[39m\u001b[38;5;124m'\u001b[39m: columns[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     36\u001b[0m         }\n\u001b[1;32m     37\u001b[0m     )\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m libwriters\u001b[38;5;241m.\u001b[39mwrite_csv_rows(\n\u001b[1;32m    314\u001b[0m     data,\n\u001b[1;32m    315\u001b[0m     ix,\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels,\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter,\n\u001b[1;32m    319\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: need to escape, but no escapechar set"
     ]
    }
   ],
   "source": [
    "from csv import reader, QUOTE_NONE\n",
    "from pandas import set_option, read_excel, read_csv, merge\n",
    "from numpy import array\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "set_option('display.max_columns', None)\n",
    "\n",
    "columns = [\n",
    "    'Group1_Tech_Annotations',\n",
    "    'Group1_Politics_Annotations',\n",
    "    'Group2_Tech_Annotations',\n",
    "    'Group2_Politics_Annotations',\n",
    "    'parent_id',\n",
    "    'Body'\n",
    "]\n",
    "\n",
    "def convert_excel_to_csv():\n",
    "    group1_df = read_excel('group1_annotations.xlsx').rename(\n",
    "        columns = {\n",
    "        'Tech Related': columns[0],\n",
    "        'Politics Related': columns[1],\n",
    "        }\n",
    "    )\n",
    "    group1_df.to_csv('annotations1.csv', index=False)\n",
    "    # print(group1_df)\n",
    "\n",
    "    group2_df = read_excel('group2_annotations.xlsx').rename(\n",
    "        columns = {\n",
    "        'Tech Related': columns[2],\n",
    "        'Politics Related': columns[3],\n",
    "        }\n",
    "    ).sort_values('parent_id')\n",
    "    print(group2_df)\n",
    "    group2_df.to_csv('annotations2.csv', index=False)\n",
    "\n",
    "convert_excel_to_csv()\n",
    "\n",
    "\n",
    "converted_df_to_list = []\n",
    "group1_df = read_csv('annotations1.csv')\n",
    "# for idx, row in group1_df.iterrows():\n",
    "    # print(row[columns[0]].strip)\n",
    "    # row[columns[2]],\n",
    "    # row[columns[1]],\n",
    "    # row[columns[3]],\n",
    "\n",
    "print(group1_df['Body'].count())\n",
    "group2_df = read_csv('annotations2.csv')\n",
    "print(group2_df['Body'].count())\n",
    "merged_df = merge(group1_df, group2_df, on=[columns[4], columns[5]])\n",
    "print(merged_df['Body'].count())\n",
    "merged_df.to_csv('test.csv', index=False)\n",
    "merged_df[columns[0]] = merged_df[columns[0]].str.upper()\n",
    "merged_df[columns[2]] = merged_df[columns[2]].str.upper()\n",
    "merged_df[columns[1]] = merged_df[columns[1]].str.upper()\n",
    "merged_df[columns[3]] = merged_df[columns[3]].str.upper()\n",
    "\n",
    "group1_tech = merged_df[columns[0]].to_numpy(dtype=str)\n",
    "group2_tech = merged_df[columns[2]].to_numpy(dtype=str)\n",
    "group1_politics = merged_df[columns[1]].to_numpy(dtype=str)\n",
    "group2_politics = merged_df[columns[3]].to_numpy(dtype=str)\n",
    "# print(group1_tech)\n",
    "\n",
    "reformat_group1_tech = []\n",
    "for row in group1_tech:\n",
    "    row = row.strip()\n",
    "    if row == 'T':\n",
    "        val = 'Y'\n",
    "        reformat_group1_tech.append(val)\n",
    "    elif row == 'nan':\n",
    "        val = 'Y'\n",
    "        reformat_group1_tech.append(val)\n",
    "    else:\n",
    "        reformat_group1_tech.append(row)\n",
    "group1_tech = reformat_group1_tech\n",
    "\n",
    "reformat_group1_politics = []\n",
    "for row in group1_politics:\n",
    "    row = row.strip()\n",
    "    reformat_group1_politics.append(row)\n",
    "# print(reformat_group1_politics)\n",
    "group1_politics = reformat_group1_politics \n",
    "\n",
    "merged_df[columns[0]] = group1_tech\n",
    "merged_df[columns[1]] = group1_politics\n",
    "print(merged_df['Group1_Tech_Annotations'].value_counts())\n",
    "\n",
    "X_dicts = []\n",
    "y = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    tmp = {\n",
    "        'g1_tech': row[columns[0]],\n",
    "        'g2_tech': row[columns[2]],\n",
    "        'g1_pol': row[columns[1]],\n",
    "        'g2_pol': row[columns[3]],\n",
    "    }\n",
    "    X_dicts.append(tmp)\n",
    "    y.append(row[columns[5]])\n",
    "\n",
    "# print(X_dicts)\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(X_dicts)\n",
    "y = array(y)\n",
    "# print(X)\n",
    "# print(y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape)\n",
    "\n",
    "clf = SVC(C=.1)\n",
    "clf = SVC(C=100.)\n",
    "# clf = SVC(C=10.)\n",
    "# clf = SVC(C=10000.)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_val)\n",
    "print(accuracy_score(y_val, preds))\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, preds))\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "\n",
    "group1_counts = {}\n",
    "for r1, r2 in zip(group1_tech, group2_tech):\n",
    "    group1_counts['r1_'+r1+'_r2_'+r2] = group1_counts.get('r1_'+r1+'_r2_'+r2, 0) + 1\n",
    "# print(group1_counts)\n",
    "\n",
    "group2_counts = {}\n",
    "for r1, r2 in zip(group1_politics, group2_politics):\n",
    "    group2_counts['r1_'+r1+'_r2_'+r2] = group2_counts.get('r1_'+r1+'_r2_'+r2, 0) + 1\n",
    "# print(group2_counts)\n",
    "# print(group1_tech)\n",
    "# print(merged_df)\n",
    "\n",
    "print('Cohen kappa tech score: ', cohen_kappa_score(group1_tech, group2_tech))\n",
    "print('Cohen kappa politics score: ', cohen_kappa_score(group1_politics, group2_politics))\n",
    "\n",
    "\n",
    "# for idx, row in merged_df.iterrows():\n",
    "#     row_list = [row[columns[4]], row[columns[5]], row[columns[0]], row[columns[2]], row[columns[1]], row[columns[3]]]\n",
    "#     converted_df_to_list.append(row_list)\n",
    "# print(converted_df_to_list)\n",
    "\n",
    "# X_txt_train = []\n",
    "# y_train = []\n",
    "# for row in converted_df_to_list:\n",
    "#     print(row)\n",
    "#     X_txt_train.append(row[1])\n",
    "#     y_train.append(row[2:])\n",
    "\n",
    "# print(X_txt_train)\n",
    "# print(y_train)\n",
    "# print(converted_df_to_list)\n",
    "# print(df)\n",
    "# data = open(\"annotations1.csv\")\n",
    "# read_data = reader(data, delimiter='\\t', quoting=QUOTE_NONE)\n",
    "\n",
    "# for row in read_data:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
